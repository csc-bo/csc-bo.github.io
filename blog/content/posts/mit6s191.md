+++
title = 'Notes for MIT 6.S191'
date = 2024-05-01T21:52:19+08:00
draft = false
+++

## 1. Introduction to Deep Learning

- After watch one of Feifei Li and Geffery Hinton's video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials.

## 2. Course Content

1. **Leture 1: Introductin**
    - The Perceptron
        1. Perceptron: Simplified
            ![perceptron](/MIT6.S191/perceptron.png)
            * **Activation Functions** is to introduce **non-linearites** into the network
                * Sigmoid
                * Hyperbolic Tangent
                * Rectified Linear Unit(ReLU)
                * We can implement this graph on code very easily
            * **One perceptron**: Draws a line to separate data. binary classification.
            * **Multiple perceptrons** in layers: Can create complex curves and shapes to separate data
            * What does it do?
            Essentially, a perceptron learns a linear decision boundary that separates the input space into two regions, each corresponding to a different class.            
        2. **Forward Propagation**:

             refers to the calculation and storage of intermediate variables (including outputs) for a neural network in order from the input to the output layer.


    - The Neural Networks
        1. Neural Network: 
            Stacking Perceptrons to form neural network
            ![SLNN](/MIT6.S191/SLNN.png)
            * -> MLP: Multi Layer Perceptron
        2. **Loss**: 
            The **loss** of our network measures the cost incurred from incorrect 

            * Empirical Loss

                The empirical loss measures the total loss over our entire dataset. Also know as Objective function, Cost function, Empirical Risk
                $$
                J(W) = \frac{1}{n} \sum_{i=1}^{n} L(f(x_i;W),y_i)
                $$

            * Binary Cross Entropy Loos
                $$
                J(W) = - \frac{1}{n} \sum_{i=1}^{n} \log(f(x_i;W)) + (1-y_i) log(1-f(x_i;W))
                $$
                
            * Mean Squared Error Loss
                $$
                J(W) = \frac{1}{n} \sum_{i=1}^{n} (y_i - f(x_i;W))^2
                 $$

            3. **Loss Optimization**
                
                - $$
                    \begin{aligned}
                    W^* = \arg \mathop{min}\limits_{W} \frac{1}{n} \sum_{i=1}^{n} L(f(x_i;W),y_i)\\
                    W^* = \arg \mathop{min}\limits_{W} J(W)\\
                    \text {Where as: } W=\{W_0, W_1, ...\}
                    \end{aligned}
                $$

                - We want to **find** the network weights that achieve the **lowest loss**
                - Our loss is a function of the network weights
                - We can use gradient descent to find the weights that minimize the loss

            4. **Gradient Descent**

                1. Initialize weights randomly $\sim N(0,\sigma^2)$
                2. Loop until convergence
                3. &nbsp;&nbsp; Compute gradients, $ \frac{\partial J(W)}{\partial W}$
                4. &nbsp;&nbsp; Update weights: $ W \leftarrow W - \eta \frac{\partial J(W)}{\partial W}$
                5. Return weights

                - **Backpropagation**: 

                    Backpropagation is the application of gradient descent in deep learning, used to compute gradients of weights in neural networks. It employs the **chain rule** from calculus to efficiently propagate errors backwards, guiding updates to each layer's parameters. By calculating the partial derivatives of the loss function with respect to every weight, it determines how each weight should be adjusted to minimize the loss.


                - **Learning Rate**

                    Momentum or Adaptive Learning Rates: For improved convergence, incorporate momentum or adaptive learning rate techniques like Nesterov Accelerated Gradient (NAG), RMSprop, or Adam.

                - **Mini-Batch Gradient Descent**

                    Instead of using all data points at once, use a mini-batch of B data points to compute the gradient. This reduces the computational cost and improves convergence.
                    $$
                        \frac{\partial J(W)}{\partial W} = \frac{1}{B} \sum_{i=1}^{B} \frac{\partial J_k(W)}{\partial W}\\
                    $$
                    $$
                        \text {Then update weights: }W \leftarrow W - \eta \frac{\partial J(W)}{\partial W}
                    $$
                    - More accurate estimation of gradient
                    - Allow for larger learning rates
                    - Smoother convergence
                    - Fast training! Can parallelize computation and achieve significant speed increases on GPU's
                3. **Optimization Algorithm**
                    * SGD(Stochastic Gradient Descent)
                    * Adam
                    * Adadelta
                    * Adagrad
                    * RMSProp


            
        3. **Real World Technique** 
            1. Mini-batches
            2. **Fitting**
                * Underfitting: Model does not have capacity to fully learn the data
                * Ideal fit
                * Overfitting: Too complex, extra parameters, does not generalize well
            3. **Regularization**: Improve generalization of our model on unseen data
                1. **Dropout**
                    During training, randomly set some activations to 0
                    * Typically 'drop' 50% of activations in layer
                    * Forces network to not rely on any 1 node

                        ![dropout](/MIT6.S191/dropout.png)

                2. **Early Stopping**

                    * Stop training before we have a chance to overfit
                    ![earlystopping](/MIT6.S191/earlystopping.png)

2. **Leture 2: Deep Sequence Modeling**
3. **Leture 3: Deep Computer Vision**
4. **Leture 4: Deep Generative Modeling**
5. **Leture 5: Deep Reinforcement Learning**
6. **Lecture 6: Limitation and New Frontiers**

-  Module Summaries: Briefly summarize each module of the course, highlighting key concepts and algorithms covered.
-  Lecture Notes: You can include your personal notes from lectures, focusing on important points and areas of difficulty.
*  Assignments and Projects: Discuss the assignments and projects assigned in the course, sharing your approach and solutions.

## 3. Resources

- Share any additional resources you found helpful while taking the course, such as:

- Online Tutorials: Links to relevant online tutorials or articles that provide further explanation on specific topics.
- Research Papers: References to important research papers in the field of deep learning.
- Software Libraries: Information about deep learning libraries used in the course, such as TensorFlow or PyTorch. 
## 4. Personal Insights and Reflections

Share your personal thoughts and reflections on the course, including:

- Challenges Faced: Discuss any challenges you encountered while learning the material and how you overcame them.
- Key Takeaways: Highlight the most important things you learned from the course.
Future Applications: Explore potential applications of deep learning that you find interesting. 5. Conclusion

Conclude your post by summarizing your experience with the course and expressing your thoughts on the field of deep learning as a whole.
