<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Notes for MIT 6.S191 | Bo's Log | What I cannot create, I do not understand</title>
<meta name=keywords content><meta name=description content="1. Introduction to Deep Learning After watch one of Feifei Li and Geffery Hinton&rsquo;s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials."><meta name=author content="Bo Liu"><link rel=canonical href=https://csc-bo.github.io/posts/mit6s191/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://csc-bo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://csc-bo.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://csc-bo.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://csc-bo.github.io/apple-touch-icon.png><link rel=mask-icon href=https://csc-bo.github.io/android-chrome-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://csc-bo.github.io/posts/mit6s191/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Notes for MIT 6.S191"><meta property="og:description" content="1. Introduction to Deep Learning After watch one of Feifei Li and Geffery Hinton&rsquo;s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials."><meta property="og:type" content="article"><meta property="og:url" content="https://csc-bo.github.io/posts/mit6s191/"><meta property="og:image" content="https://csc-bo.github.io/favicon.ico"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-01T21:52:19+08:00"><meta property="article:modified_time" content="2024-05-01T21:52:19+08:00"><meta property="og:site_name" content="Bo's Log"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://csc-bo.github.io/favicon.ico"><meta name=twitter:title content="Notes for MIT 6.S191"><meta name=twitter:description content="1. Introduction to Deep Learning After watch one of Feifei Li and Geffery Hinton&rsquo;s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://csc-bo.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Notes for MIT 6.S191","item":"https://csc-bo.github.io/posts/mit6s191/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Notes for MIT 6.S191","name":"Notes for MIT 6.S191","description":"1. Introduction to Deep Learning After watch one of Feifei Li and Geffery Hinton\u0026rsquo;s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials.","keywords":[],"articleBody":"1. Introduction to Deep Learning After watch one of Feifei Li and Geffery Hinton’s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials. 2. Course Content Leture 1: Introductin\nThe Perceptron\nPerceptron: Simplified Activation Functions is to introduce non-linearites into the network Sigmoid Hyperbolic Tangent Rectified Linear Unit(ReLU) We can implement this graph on code very easily One perceptron: Draws a line to separate data. binary classification. Multiple perceptrons in layers: Can create complex curves and shapes to separate data What does it do? Essentially, a perceptron learns a linear decision boundary that separates the input space into two regions, each corresponding to a different class. Forward Propagation/Forward Pass:\nrefers to the calculation and storage of intermediate variables (including outputs) for a neural network in order from the input to the output layer.\nThe Neural Networks\nNeural Network: Stacking Perceptrons to form neural network -\u003e MLP: Multi Layer Perceptron Loss: The loss of our network measures the cost incurred from incorrect\nEmpirical Loss\nThe empirical loss measures the total loss over our entire dataset. Also know as Objective function, Cost function, Empirical Risk $$\rJ(W) = \\frac{1}{n} \\sum_{i=1}^{n} L(f(x_i;W),y_i)\r$$ Binary Cross Entropy Loos $$\rJ(W) = - \\frac{1}{n} \\sum_{i=1}^{n} \\log(f(x_i;W)) + (1-y_i) log(1-f(x_i;W))\r$$ Mean Squared Error Loss $$\rJ(W) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - f(x_i;W))^2\r$$ Loss Optimization\n$$\r\\begin{aligned}\rW^* = \\arg \\mathop{min}\\limits_{W} \\frac{1}{n} \\sum_{i=1}^{n} L(f(x_i;W),y_i)\\\\\rW^* = \\arg \\mathop{min}\\limits_{W} J(W)\\\\\r\\text {Where as: } W=\\{W_0, W_1, ...\\}\r\\end{aligned}\r$$ We want to find the network weights that achieve the lowest loss\nOur loss is a function of the network weights\nWe can use gradient descent to find the weights that minimize the loss\nGradient Descent\nInitialize weights randomly $\\sim N(0,\\sigma^2)$ Loop until convergence Compute gradients, $ \\frac{\\partial J(W)}{\\partial W}$ Update weights: $ W \\leftarrow W - \\eta \\frac{\\partial J(W)}{\\partial W}$ Return weights Backpropagation:\nBackpropagation is the application of gradient descent in deep learning, used to compute gradients of weights in neural networks. It employs the chain rule from calculus to efficiently propagate errors backwards, guiding updates to each layer’s parameters. By calculating the partial derivatives of the loss function with respect to every weight, it determines how each weight should be adjusted to minimize the loss.\nLearning Rate\nMomentum or Adaptive Learning Rates: For improved convergence, incorporate momentum or adaptive learning rate techniques like Nesterov Accelerated Gradient (NAG), RMSprop, or Adam.\nMini-Batch Gradient Descent\nInstead of using all data points at once, use a mini-batch of B data points to compute the gradient. This reduces the computational cost and improves convergence. $$\r\\frac{\\partial J(W)}{\\partial W} = \\frac{1}{B} \\sum_{i=1}^{B} \\frac{\\partial J_k(W)}{\\partial W}\\\\\r$$ $$\r\\text {Then update weights: }W \\leftarrow W - \\eta \\frac{\\partial J(W)}{\\partial W}\r$$ More accurate estimation of gradient Allow for larger learning rates Smoother convergence Fast training! Can parallelize computation and achieve significant speed increases on GPU’s Optimization Algorithm SGD(Stochastic Gradient Descent) Adam Adadelta Adagrad RMSProp Real World Technique\nMini-batches Fitting Underfitting: Model does not have capacity to fully learn the data Ideal fit Overfitting: Too complex, extra parameters, does not generalize well Regularization: Improve generalization of our model on unseen data Dropout During training, randomly set some activations to 0\nTypically ‘drop’ 50% of activations in layer\nForces network to not rely on any 1 node\nEarly Stopping\nStop training before we have a chance to overfit Leture 2: Deep Sequence Modeling\nI’m gonna write this note in a more practical way, and from my SDE perspective. Code is nessesary for me to understand the concept.\nRecurrent Neural Networks(RNNs)\nMany to One: Sentiment Classification One to Many: Text Generation, Image Captioning Many to Many: Translation \u0026 Forecasting, Music Generation class myRNNCell(tf.keras.layers.Layer):\rdef __init__(self, rnn_units, input_dim, output_dim):\rsuper(myRNNCell, self).__init__()\r# Initialize weight matrices\rself.W_xh = self.add_weight([rnn_units, input_dim])\rself.W_hh = self.add_weight([rnn_units, rnn_units])\rself.W_hy = self.add_weight([output_dim, rnn_units])\r# Initialize hidden state to zeros\rself.h = tf.zeros([rnn_units, 1])\rdef call(self, x):\r# the input x corresponds to x_t in the graph\r# Update the hidden state\r# h_t = tanh(W_hh * h_{t-1} + W_xh * x_t)\rself.h = tf.math.tanh( self.W_hh * self.h + self.W_xh * x)\r# Compute the output, y^hat_t = W_hy * h\routput = self.W_hy * self.h\r# Return the current output and hidden state\rreturn output, self.h\r# tensorflow method\rtf.keras.layers.SimpleRNN(rnn_units) The implementation is highly identical to the graphical representation. This code provided by Professor slide not complete. But we can get the idea. I watched Andrej Karpathy’s video, he actully only need an image to implement Neural Networks. Combine the graph and code help me to understand the concept. Endcoding Language for a Neural Network\nEmbbedding: transform indexes into a vector of fixed size. One-hot embedding: One-hot embedding is a way to represent categorical data as binary vectors. Each category is represented by a binary vector, where only one element is 1, and the rest are 0. This representation is useful for representing categorical data, such as words in a language, where each word is represented by a unique index. RNN feedforwar and backpropagation graph RNN Problems\nExploding Gradients: Many values \u003e 1, mutiply many large numbers together lead to unstable training, oscillations in the loss function, and ultimately, the model failing to converge to a good solution. Gradient clipping: A technique used to prevent exploding gradients by clipping the gradients to a maximum value. Vanishing Gradients: Many values \u003c 1, mutiply many small numbers together cause the weights to not update at all. then the bias parameters capture short-term dependencies. result no long-term dependencies. Activation functions: Using ReLU prevents f’ from shriking the gradients when x \u003e 0 Parameter Initialization: Initializing weights to identity matrix, initialize biases to zero. this prevent the weight from shrinking to zero Gated Cells: use gates to selectively add or remove information within each recurrent unit with gated cell (LSTMs, GRUs) LSTMs(Long Short-Term Memory)\nGated LSTM cells control information flow Key Concepts Maintain a cell state Use gates to control the flow of information Forget gate gets rid of irrelevant information Store relevent information from current input Selectively update cell state Output gate returns a filtered version of the cell state Backpropagation through time with partially uninterrupted gradient flow Limitations of RNNs\nEncoding bottleneck Slow, no parallelization Not long memory Attention is all you need(transformer)\nAttention mechanism: orignal from a paper of RNN, this is like RNN search. Allow network to search relevant information Self-Attention: identify and attend to most important features in input Encode position information Extract query, key, value for search Comput attention weighting Extract Features with high attention These steps form a self-attention head that plug into a larger network. Each head attends to a different part of the input. Self-Attention Applied: Language Model: Transformers, GPT, BERT Biological Sequence: AlphaFold2 Computer Vison: Vision Transformers Tranfomer Structure Leture 3: Deep Computer Vision\nFoundation: Images are numbers 2D image Vector of pixel values Convolution extract features with convolution Steps: Apply a set of weights - a filter - to extract local features Use multiple filters to extract different features Spatially share parameters of each filter CNNs(Convolutional Neural Networks) Convolution: Apply filters to generate feature maps Non-linearity: Often ReLU Pooling: Downsampling operation on each feature map. import tensorflow as tf\rdef generate_model():\rmodel = tf.keras.Sequential([\r# first convolutional layer\rtf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\rtf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\r# second convolutional layer\rtf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\rtf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\r# fully connected classifier\rtf.keras.layers.Flatten(),\rtf.keras.layers.Dense(1024, activation='relu'),\rtf.keras.layers.Dense(10, activation='softmax') # 10 outputs\r])\rreturn model Applications Classification Breast Cancer Screening Object Detection R-CNNs alorithm: Find regions that we think have objects. Use CNN to classify Semantic Segmentation: Fully Convolutional Networks(FCN) Biomedical Image Analysis Navigation from Vision End-to-End Autonomos Navigation Leture 4: Deep Generative Modeling\nSupervised/Unsupervised Learning Gnerative Models Debiasing Outlier Detection VAEs (Autoencoders and Variational Autoencoders) Autoencoders GANS (Generative Adversarial Networks) Basic Concepts Applications Leture 5: Deep Reinforcement Learning\nRL Concepts Agent Environment Actions Observations State Reward The Q-function captures the expected total future reward an agent in state,s, can receive by executing a certain action,a RL Learning Algorithms Value Learning Policy Learning DQN (Deep Q-Networks) Concepts Training Summary Downside of Q-learning Complexity Can model scenarios where the action space is discrete and small Cannot handle continuous action spaces Flexibility Policy is deterministically computed from the Q function by maximizing the reward Cannot learn stochastic policies Policy Gradient Methods Key ideas Directly optimize the policy pi(s) Continuouse action spaces Traning Initialize the agent Run a policy until termination Record all states, actions, rewards Decrease probability of actions that resulted in low reward Increase probability of actions that resulted in high reward Applications Alpha Go Lecture 6: Limitation and New Frontiers\nModule Summaries: Briefly summarize each module of the course, highlighting key concepts and algorithms covered. Lecture Notes: You can include your personal notes from lectures, focusing on important points and areas of difficulty. Assignments and Projects: Discuss the assignments and projects assigned in the course, sharing your approach and solutions. 3. Resources Share any additional resources you found helpful while taking the course, such as:\nOnline Tutorials: Links to relevant online tutorials or articles that provide further explanation on specific topics.\nResearch Papers: References to important research papers in the field of deep learning.\nSoftware Libraries: Information about deep learning libraries used in the course, such as TensorFlow or PyTorch.\n4. Personal Insights and Reflections Share your personal thoughts and reflections on the course, including:\nChallenges Faced: Discuss any challenges you encountered while learning the material and how you overcame them. Key Takeaways: Highlight the most important things you learned from the course. Future Applications: Explore potential applications of deep learning that you find interesting. 5. Conclusion Conclude your post by summarizing your experience with the course and expressing your thoughts on the field of deep learning as a whole.\n","wordCount":"1675","inLanguage":"en","image":"https://csc-bo.github.io/favicon.ico","datePublished":"2024-05-01T21:52:19+08:00","dateModified":"2024-05-01T21:52:19+08:00","author":{"@type":"Person","name":"Bo Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://csc-bo.github.io/posts/mit6s191/"},"publisher":{"@type":"Organization","name":"Bo's Log | What I cannot create, I do not understand","logo":{"@type":"ImageObject","url":"https://csc-bo.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://csc-bo.github.io/ accesskey=h title="Bo's Log (Alt + H)"><img src=https://csc-bo.github.io/apple-touch-icon.png alt aria-label=logo height=35>Bo's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://csc-bo.github.io/ title=Home><span>Home</span></a></li><li><a href=https://csc-bo.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://csc-bo.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://csc-bo.github.io/experience/ title=Experience><span>Experience</span></a></li><li><a href=https://csc-bo.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://csc-bo.github.io/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://csc-bo.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://csc-bo.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Notes for MIT 6.S191</h1><div class=post-meta><span title='2024-05-01 21:52:19 +0800 CST'>May 1, 2024</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1675 words&nbsp;·&nbsp;Bo Liu&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/mit6s191.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#1-introduction-to-deep-learning>1. Introduction to Deep Learning</a></li><li><a href=#2-course-content>2. Course Content</a></li><li><a href=#3-resources>3. Resources</a></li><li><a href=#4-personal-insights-and-reflections>4. Personal Insights and Reflections</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=1-introduction-to-deep-learning>1. Introduction to Deep Learning<a hidden class=anchor aria-hidden=true href=#1-introduction-to-deep-learning>#</a></h2><ul><li>After watch one of Feifei Li and Geffery Hinton&rsquo;s video on Youtube, I start to gain interest in DeepLearning, then I found this MIT course online that is a very comprehensive introduction for the Deep Learning which perfect for beginners like myself. This blog post marks the beginning of my journey into the world of machine learning, serving as a collection for my course notes and insights from related materials.</li></ul><h2 id=2-course-content>2. Course Content<a hidden class=anchor aria-hidden=true href=#2-course-content>#</a></h2><ol><li><p><strong>Leture 1: Introductin</strong></p><ul><li><p>The Perceptron</p><ol><li><p>Perceptron: Simplified
<img loading=lazy src=/MIT6.S191/perceptron.png alt=perceptron></p><ul><li><strong>Activation Functions</strong> is to introduce <strong>non-linearites</strong> into the network<ul><li>Sigmoid</li><li>Hyperbolic Tangent</li><li>Rectified Linear Unit(ReLU)</li><li>We can implement this graph on code very easily</li></ul></li><li><strong>One perceptron</strong>: Draws a line to separate data. binary classification.</li><li><strong>Multiple perceptrons</strong> in layers: Can create complex curves and shapes to separate data</li><li>What does it do?
Essentially, a perceptron learns a linear decision boundary that separates the input space into two regions, each corresponding to a different class.</li></ul></li><li><p><strong>Forward Propagation/Forward Pass</strong>:</p><p>refers to the calculation and storage of intermediate variables (including outputs) for a neural network in order from the input to the output layer.</p></li></ol></li><li><p>The Neural Networks</p><ol><li><p>Neural Network:
Stacking Perceptrons to form neural network
<img loading=lazy src=/MIT6.S191/SLNN.png alt=SLNN></p><ul><li>-> MLP: Multi Layer Perceptron</li></ul></li><li><p><strong>Loss</strong>:
The <strong>loss</strong> of our network measures the cost incurred from incorrect</p><ul><li><p>Empirical Loss</p><p>The empirical loss measures the total loss over our entire dataset. Also know as Objective function, Cost function, Empirical Risk</p>$$
J(W) = \frac{1}{n} \sum_{i=1}^{n} L(f(x_i;W),y_i)
$$</li><li><p>Binary Cross Entropy Loos</p>$$
J(W) = - \frac{1}{n} \sum_{i=1}^{n} \log(f(x_i;W)) + (1-y_i) log(1-f(x_i;W))
$$</li><li><p>Mean Squared Error Loss</p>$$
J(W) = \frac{1}{n} \sum_{i=1}^{n} (y_i - f(x_i;W))^2
$$</li></ul><ol start=3><li><p><strong>Loss Optimization</strong></p><ul><li>$$
\begin{aligned}
W^* = \arg \mathop{min}\limits_{W} \frac{1}{n} \sum_{i=1}^{n} L(f(x_i;W),y_i)\\
W^* = \arg \mathop{min}\limits_{W} J(W)\\
\text {Where as: } W=\{W_0, W_1, ...\}
\end{aligned}
$$</li><li><p>We want to <strong>find</strong> the network weights that achieve the <strong>lowest loss</strong></p></li><li><p>Our loss is a function of the network weights</p></li><li><p>We can use gradient descent to find the weights that minimize the loss</p></li></ul></li><li><p><strong>Gradient Descent</strong></p><ol><li>Initialize weights randomly $\sim N(0,\sigma^2)$</li><li>Loop until convergence</li><li>   Compute gradients, $ \frac{\partial J(W)}{\partial W}$</li><li>   Update weights: $ W \leftarrow W - \eta \frac{\partial J(W)}{\partial W}$</li><li>Return weights</li></ol><ul><li><p><strong>Backpropagation</strong>:</p><p>Backpropagation is the application of gradient descent in deep learning, used to compute gradients of weights in neural networks. It employs the <strong>chain rule</strong> from calculus to efficiently propagate errors backwards, guiding updates to each layer&rsquo;s parameters. By calculating the partial derivatives of the loss function with respect to every weight, it determines how each weight should be adjusted to minimize the loss.</p></li><li><p><strong>Learning Rate</strong></p><p>Momentum or Adaptive Learning Rates: For improved convergence, incorporate momentum or adaptive learning rate techniques like Nesterov Accelerated Gradient (NAG), RMSprop, or Adam.</p></li><li><p><strong>Mini-Batch Gradient Descent</strong></p><p>Instead of using all data points at once, use a mini-batch of B data points to compute the gradient. This reduces the computational cost and improves convergence.</p>$$
\frac{\partial J(W)}{\partial W} = \frac{1}{B} \sum_{i=1}^{B} \frac{\partial J_k(W)}{\partial W}\\
$$
$$
\text {Then update weights: }W \leftarrow W - \eta \frac{\partial J(W)}{\partial W}
$$<ul><li>More accurate estimation of gradient</li><li>Allow for larger learning rates</li><li>Smoother convergence</li><li>Fast training! Can parallelize computation and achieve significant speed increases on GPU&rsquo;s</li></ul></li></ul><ol start=3><li><strong>Optimization Algorithm</strong><ul><li>SGD(Stochastic Gradient Descent)</li><li>Adam</li><li>Adadelta</li><li>Adagrad</li><li>RMSProp</li></ul></li></ol></li></ol></li><li><p><strong>Real World Technique</strong></p><ol><li>Mini-batches</li><li><strong>Fitting</strong><ul><li>Underfitting: Model does not have capacity to fully learn the data</li><li>Ideal fit</li><li>Overfitting: Too complex, extra parameters, does not generalize well</li></ul></li><li><strong>Regularization</strong>: Improve generalization of our model on unseen data<ol><li><p><strong>Dropout</strong>
During training, randomly set some activations to 0</p><ul><li><p>Typically &lsquo;drop&rsquo; 50% of activations in layer</p></li><li><p>Forces network to not rely on any 1 node</p><p><img loading=lazy src=/MIT6.S191/dropout.png alt=dropout></p></li></ul></li><li><p><strong>Early Stopping</strong></p><ul><li>Stop training before we have a chance to overfit
<img loading=lazy src=/MIT6.S191/earlystopping.png alt=earlystopping></li></ul></li></ol></li></ol></li></ol></li></ul></li><li><p><strong>Leture 2: Deep Sequence Modeling</strong></p><ul><li><p>I&rsquo;m gonna write this note in a more practical way, and from my SDE perspective. Code is nessesary for me to understand the concept.</p></li><li><p>Recurrent Neural Networks(RNNs)</p><ul><li>Many to One: Sentiment Classification</li><li>One to Many: Text Generation, Image Captioning</li><li>Many to Many: Translation & Forecasting, Music Generation
<img loading=lazy src=image.png alt="alt text">
<img loading=lazy src=/MIT6.S191/RNN.png alt=RNN></li></ul><pre tabindex=0><code>class myRNNCell(tf.keras.layers.Layer):
    def __init__(self, rnn_units, input_dim, output_dim):
        super(myRNNCell, self).__init__()

        # Initialize weight matrices
        self.W_xh = self.add_weight([rnn_units, input_dim])
        self.W_hh = self.add_weight([rnn_units, rnn_units])
        self.W_hy = self.add_weight([output_dim, rnn_units])

        # Initialize hidden state to zeros
        self.h = tf.zeros([rnn_units, 1])

    def call(self, x):
        # the input x corresponds to x_t in the graph

        # Update the hidden state
        # h_t = tanh(W_hh * h_{t-1} + W_xh * x_t)
        self.h = tf.math.tanh(  self.W_hh * self.h + self.W_xh * x)

        # Compute the output, y^hat_t = W_hy * h
        output = self.W_hy * self.h

        # Return the current output and hidden state
        return output, self.h

# tensorflow method
tf.keras.layers.SimpleRNN(rnn_units)
</code></pre><ul><li>The implementation is highly identical to the graphical representation.</li><li>This code provided by Professor slide not complete. But we can get the idea.</li><li>I watched Andrej Karpathy&rsquo;s video, he actully only need an image to implement Neural Networks.</li><li>Combine the graph and code help me to understand the concept.</li></ul></li><li><p>Endcoding Language for a Neural Network</p><ul><li><strong>Embbedding</strong>: transform indexes into a vector of fixed size.
<img loading=lazy src=image-2.png alt="alt text"></li><li><strong>One-hot embedding</strong>:<ul><li>One-hot embedding is a way to represent categorical data as binary vectors.</li><li>Each category is represented by a binary vector, where only one element is 1, and the rest are 0.</li><li>This representation is useful for representing categorical data, such as words in a language, where each word is represented by a unique index.</li></ul></li></ul></li><li><p>RNN feedforwar and backpropagation graph
<img loading=lazy src=image-1.png alt="alt text"></p></li><li><p>RNN Problems</p><ul><li>Exploding Gradients: Many values > 1, mutiply many large numbers together lead to unstable training, oscillations in the loss function, and ultimately, the model failing to converge to a good solution.<ul><li>Gradient clipping: A technique used to prevent exploding gradients by clipping the gradients to a maximum value.</li></ul></li><li>Vanishing Gradients: Many values &lt; 1, mutiply many small numbers together cause the weights to not update at all. then the bias parameters capture short-term dependencies. result no long-term dependencies.<ul><li>Activation functions: Using ReLU prevents f&rsquo; from shriking the gradients when x > 0</li><li>Parameter Initialization: Initializing <strong>weights</strong> to identity matrix, initialize <strong>biases</strong> to zero. this prevent the weight from shrinking to zero</li><li>Gated Cells: use gates to selectively add or remove information within each recurrent unit with gated cell (LSTMs, GRUs)</li></ul></li></ul></li><li><p>LSTMs(Long Short-Term Memory)</p><ul><li>Gated LSTM cells control information flow</li><li>Key Concepts<ol><li>Maintain a <strong>cell state</strong></li><li>Use <strong>gates</strong> to control the <strong>flow of information</strong><ul><li><strong>Forget</strong> gate gets rid of irrelevant information</li><li><strong>Store</strong> relevent information from current input</li><li>Selectively <strong>update</strong> cell state</li><li><strong>Output</strong> gate returns a filtered version of the cell state</li></ul></li><li>Backpropagation through time with partially <strong>uninterrupted gradient flow</strong></li></ol></li></ul></li><li><p>Limitations of RNNs</p><ul><li>Encoding bottleneck</li><li>Slow, no parallelization</li><li>Not long memory</li></ul></li><li><p>Attention is all you need(transformer)</p><ul><li>Attention mechanism: orignal from a paper of RNN, this is like RNN search. Allow network to search relevant information</li><li>Self-Attention: identify and attend to most important features in input<ol><li>Encode <strong>position</strong> information</li><li>Extract <strong>query, key, value</strong> for search</li><li>Comput <strong>attention weighting</strong></li><li>Extract <strong>Features with high attention</strong>
These steps form a self-attention head that plug into a larger network. Each head attends to a different part of the input.</li></ol></li><li>Self-Attention Applied:<ul><li>Language Model: Transformers, GPT, BERT</li><li>Biological Sequence: AlphaFold2</li><li>Computer Vison: Vision Transformers</li></ul></li><li>Tranfomer Structure
<img loading=lazy src=image-3.png alt="alt text"></li></ul></li></ul></li><li><p><strong>Leture 3: Deep Computer Vision</strong></p><ul><li>Foundation:<ol><li>Images are numbers<ul><li>2D image</li><li>Vector of pixel values</li></ul></li><li>Convolution<ul><li>extract features with convolution
<img loading=lazy src=image-4.png alt="alt text"></li><li>Steps:<ol><li>Apply a set of weights - a filter - to extract <strong>local features</strong></li><li>Use <strong>multiple filters</strong> to extract different features</li><li><strong>Spatially share</strong> parameters of each filter</li></ol></li></ul></li></ol></li><li>CNNs(Convolutional Neural Networks)<ol><li>Convolution: Apply filters to generate feature maps</li><li>Non-linearity: Often ReLU</li><li>Pooling: Downsampling operation on each feature map.</li></ol><pre tabindex=0><code>import tensorflow as tf

def generate_model():
    model = tf.keras.Sequential([
        # first convolutional layer
        tf.keras.layers.Conv2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),

        # second convolutional layer
        tf.keras.layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;),
        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),

        # fully connected classifier
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation=&#39;relu&#39;),

        tf.keras.layers.Dense(10, activation=&#39;softmax&#39;) # 10 outputs
        ])
    return model
</code></pre><ul><li>Applications<ol><li>Classification<ul><li>Breast Cancer Screening</li><li>Object Detection</li><li>R-CNNs alorithm: Find regions that we think have objects. Use CNN to classify</li></ul></li><li>Semantic Segmentation: Fully Convolutional Networks(FCN)<ul><li>Biomedical Image Analysis</li></ul></li><li>Navigation from Vision</li><li>End-to-End Autonomos Navigation</li></ol></li></ul></li></ul></li><li><p><strong>Leture 4: Deep Generative Modeling</strong></p><ol><li>Supervised/Unsupervised Learning</li><li>Gnerative Models<ul><li>Debiasing</li><li>Outlier Detection</li></ul></li><li>VAEs (Autoencoders and Variational Autoencoders)<ul><li>Autoencoders</li></ul></li><li>GANS (Generative Adversarial Networks)<ul><li>Basic Concepts</li><li>Applications</li></ul></li></ol></li><li><p><strong>Leture 5: Deep Reinforcement Learning</strong></p><ul><li>RL Concepts<ul><li>Agent</li><li>Environment</li><li>Actions</li><li>Observations</li><li>State</li><li>Reward<ul><li>The Q-function captures the expected total future reward an agent in state,s, can receive by executing a certain action,a</li></ul></li></ul></li><li>RL Learning Algorithms<ul><li>Value Learning</li><li>Policy Learning</li></ul></li><li><strong>DQN (Deep Q-Networks)</strong><ul><li>Concepts</li><li>Training</li><li>Summary</li></ul></li><li>Downside of Q-learning<ul><li>Complexity<ul><li>Can model scenarios where the action space is discrete and small</li><li>Cannot handle continuous action spaces</li></ul></li><li>Flexibility<ul><li>Policy is deterministically computed from the Q function by maximizing the reward</li><li>Cannot learn stochastic policies</li></ul></li></ul></li><li><strong>Policy Gradient</strong> Methods<ul><li>Key ideas<ul><li>Directly optimize the policy pi(s)</li><li>Continuouse action spaces</li></ul></li><li>Traning<ol><li>Initialize the agent</li><li>Run a policy until termination</li><li>Record all states, actions, rewards</li><li><strong>Decrease probability of actions that resulted in low reward</strong></li><li><strong>Increase probability of actions that resulted in high reward</strong></li></ol></li></ul></li><li>Applications<ul><li>Alpha Go</li></ul></li></ul></li><li><p><strong>Lecture 6: Limitation and New Frontiers</strong></p></li></ol><ul><li>Module Summaries: Briefly summarize each module of the course, highlighting key concepts and algorithms covered.</li><li>Lecture Notes: You can include your personal notes from lectures, focusing on important points and areas of difficulty.</li></ul><ul><li>Assignments and Projects: Discuss the assignments and projects assigned in the course, sharing your approach and solutions.</li></ul><h2 id=3-resources>3. Resources<a hidden class=anchor aria-hidden=true href=#3-resources>#</a></h2><ul><li><p>Share any additional resources you found helpful while taking the course, such as:</p></li><li><p>Online Tutorials: Links to relevant online tutorials or articles that provide further explanation on specific topics.</p></li><li><p>Research Papers: References to important research papers in the field of deep learning.</p></li><li><p>Software Libraries: Information about deep learning libraries used in the course, such as TensorFlow or PyTorch.</p></li></ul><h2 id=4-personal-insights-and-reflections>4. Personal Insights and Reflections<a hidden class=anchor aria-hidden=true href=#4-personal-insights-and-reflections>#</a></h2><p>Share your personal thoughts and reflections on the course, including:</p><ul><li>Challenges Faced: Discuss any challenges you encountered while learning the material and how you overcame them.</li><li>Key Takeaways: Highlight the most important things you learned from the course.
Future Applications: Explore potential applications of deep learning that you find interesting. 5. Conclusion</li></ul><p>Conclude your post by summarizing your experience with the course and expressing your thoughts on the field of deep learning as a whole.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://csc-bo.github.io/posts/roadmap_ml/><span class=title>« Prev</span><br><span>Roadmap for machine lerning</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://csc-bo.github.io/>Bo's Log | What I cannot create, I do not understand</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script></body></html>