<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cs231_part2_quiz | Bo's Log | What I cannot create, I do not understand</title>
<meta name=keywords content><meta name=description content='I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!"
Multiple Choice:
What is the primary function of a convolutional layer in a ConvNet?
a) To perform matrix multiplication on the input data. b) To extract features from the input volume by applying learnable filters. c) To classify the input data into different categories. d) To reduce the dimensionality of the input data. What does &ldquo;local connectivity&rdquo; mean in the context of convolutional layers?'><meta name=author content="Bo Liu"><link rel=canonical href=https://csc-bo.github.io/posts/cs231_part2_quiz/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://csc-bo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://csc-bo.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://csc-bo.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://csc-bo.github.io/apple-touch-icon.png><link rel=mask-icon href=https://csc-bo.github.io/android-chrome-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://csc-bo.github.io/posts/cs231_part2_quiz/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Cs231_part2_quiz"><meta property="og:description" content='I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!"
Multiple Choice:
What is the primary function of a convolutional layer in a ConvNet?
a) To perform matrix multiplication on the input data. b) To extract features from the input volume by applying learnable filters. c) To classify the input data into different categories. d) To reduce the dimensionality of the input data. What does &ldquo;local connectivity&rdquo; mean in the context of convolutional layers?'><meta property="og:type" content="article"><meta property="og:url" content="https://csc-bo.github.io/posts/cs231_part2_quiz/"><meta property="og:image" content="https://csc-bo.github.io/favicon.ico"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-21T16:18:00+08:00"><meta property="article:modified_time" content="2024-05-21T16:18:00+08:00"><meta property="og:site_name" content="Bo's Log"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://csc-bo.github.io/favicon.ico"><meta name=twitter:title content="Cs231_part2_quiz"><meta name=twitter:description content='I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!"
Multiple Choice:
What is the primary function of a convolutional layer in a ConvNet?
a) To perform matrix multiplication on the input data. b) To extract features from the input volume by applying learnable filters. c) To classify the input data into different categories. d) To reduce the dimensionality of the input data. What does &ldquo;local connectivity&rdquo; mean in the context of convolutional layers?'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://csc-bo.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Cs231_part2_quiz","item":"https://csc-bo.github.io/posts/cs231_part2_quiz/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cs231_part2_quiz","name":"Cs231_part2_quiz","description":"I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!\u0026quot;\nMultiple Choice:\nWhat is the primary function of a convolutional layer in a ConvNet?\na) To perform matrix multiplication on the input data. b) To extract features from the input volume by applying learnable filters. c) To classify the input data into different categories. d) To reduce the dimensionality of the input data. What does \u0026ldquo;local connectivity\u0026rdquo; mean in the context of convolutional layers?","keywords":[],"articleBody":"I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!\"\nMultiple Choice:\nWhat is the primary function of a convolutional layer in a ConvNet?\na) To perform matrix multiplication on the input data. b) To extract features from the input volume by applying learnable filters. c) To classify the input data into different categories. d) To reduce the dimensionality of the input data. What does “local connectivity” mean in the context of convolutional layers?\na) Each neuron is connected to all neurons in the previous layer. b) Each neuron is connected to a small region of the input volume. c) Neurons in the same depth slice share the same weights. d) The layer’s output is a single vector of class scores. Which of the following is NOT a hyperparameter that controls the size of the output volume in a convolutional layer?\na) Depth b) Stride c) Receptive field size d) Zero padding What is the purpose of parameter sharing in convolutional layers?\na) To reduce the number of parameters in the network. b) To ensure that the network is translationally invariant. c) To allow the network to learn more complex features. d) All of the above. What is a “depth slice” in a convolutional layer?\na) A 2D slice of the output volume, where all neurons share the same weights. b) A 3D volume representing the input to the convolutional layer. c) A single neuron in the convolutional layer. d) The set of all neurons connected to a specific region of the input volume. True/False:\nConvolutional layers are only used in image processing tasks. Zero padding is always necessary to preserve the spatial size of the input volume. The stride hyperparameter determines the size of the receptive field. A convolutional layer can be implemented as a matrix multiplication operation. Short Answer:\nExplain the concept of a “filter” in a convolutional layer. How does the stride hyperparameter affect the size of the output volume? Give an example of how parameter sharing contributes to translation invariance in a ConvNet. Answer Key:\nMultiple Choice:\nb) To extract features from the input volume by applying learnable filters. b) Each neuron is connected to a small region of the input volume. c) Receptive field size d) All of the above. a) A 2D slice of the output volume, where all neurons share the same weights. True/False:\nFalse False False True Short Answer:\nA filter in a convolutional layer is a set of weights that is applied to a small region of the input volume. The filter learns to detect a specific feature, such as an edge or a texture. A larger stride results in a smaller output volume, as the filter skips over more pixels in the input volume. If a ConvNet learns to detect a horizontal edge in one part of the image, parameter sharing ensures that it can also detect that edge in other parts of the image without needing to learn separate weights for each location. This makes the network translationally invariant. This quiz is designed to test your understanding of the core concepts related to convolutional layers. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.\nQuiz: Visualizing ConvNets This quiz focuses on understanding how to visualize and interpret what Convolutional Neural Networks (ConvNets) learn, based on the information from the CS231n website.\nMultiple Choice:\nWhich of the following is NOT a common technique for visualizing ConvNets?\na) Visualizing activations of different layers. b) Visualizing the weights of filters. c) Occluding parts of the image to see how the prediction changes. d) Using a fully connected layer to classify the input image. What can be inferred from seeing noisy patterns in the visualized weights of a ConvNet?\na) The network has been trained for a long time. b) The network is overfitting the training data. c) The network is performing well on unseen data. d) The network has a high regularization strength. What is a potential drawback of visualizing the images that maximally activate a neuron?\na) It can be difficult to understand the meaning of a single neuron in isolation. b) It doesn’t provide information about the spatial relationships between features. c) It requires a large dataset of images for visualization. d) All of the above. What is the purpose of using t-SNE to embed CNN codes?\na) To visualize the high-dimensional representation space of a ConvNet in two dimensions. b) To understand the spatial relationships between features learned by the network. c) To determine the optimal number of filters for a convolutional layer. d) To reduce the number of parameters in the network. What information can be obtained by occluding parts of an image and observing the change in classification probability?\na) Which parts of the image are most important for the network’s prediction. b) The specific features that the network is learning to detect. c) The size of the receptive field for each neuron in the network. d) The number of hidden layers required for accurate classification. True/False:\nVisualizing activations can help identify “dead filters” in a ConvNet. t-SNE is the only method for visualizing high-dimensional data in a low-dimensional space. Occlusion methods can be used to understand the spatial relationships between features learned by the network. Short Answer:\nExplain why visualizing the weights of the first convolutional layer is often more interpretable than visualizing weights in deeper layers. Describe one limitation of using t-SNE to visualize CNN codes. What is the difference between visualizing activations and visualizing weights in a ConvNet? Answer Key:\nMultiple Choice:\nd) Using a fully connected layer to classify the input image. b) The network is overfitting the training data. d) All of the above. a) To visualize the high-dimensional representation space of a ConvNet in two dimensions. a) Which parts of the image are most important for the network’s prediction. True/False:\nTrue False True Short Answer:\nThe first convolutional layer operates directly on raw pixel data, making the filters easier to interpret as they learn simple features like edges, textures, and colors. Deeper layers learn more abstract and complex features, making their weights harder to understand visually. t-SNE can sometimes distort the relationships between points in the high-dimensional space, especially when dealing with very large datasets. It can also be sensitive to the choice of hyperparameters. Visualizing activations shows the output of each neuron in a layer for a given input image. Visualizing weights shows the filters learned by the convolutional layer, which represent the patterns the network is looking for in the input data. This quiz is designed to help you understand the different techniques for visualizing and interpreting ConvNets. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.\nTransfer Learning in ConvNets: A Quiz This quiz focuses on the concepts of transfer learning in convolutional neural networks, as explained on the CS231n website.\nMultiple Choice:\nWhy is it uncommon to train a ConvNet from scratch?\na) It requires a large amount of data. b) It is computationally expensive. c) It is difficult to find good initial weights. d) All of the above. What is the primary benefit of using a pretrained ConvNet as a fixed feature extractor?\na) It allows for faster training times. b) It improves the performance of the network on the new dataset. c) It reduces the risk of overfitting. d) It enables the use of smaller datasets. What are “CNN codes”?\na) The weights of the convolutional layers in a pretrained ConvNet. b) The activations of the hidden layers in a pretrained ConvNet. c) The output of the classifier layer in a pretrained ConvNet. d) The input images used to train a pretrained ConvNet. Which of the following is NOT a factor to consider when deciding whether to fine-tune a pretrained ConvNet?\na) The size of the new dataset. b) The similarity of the new dataset to the original dataset. c) The number of convolutional layers in the pretrained network. d) The learning rate used for training the new classifier. What is the main advantage of using a pretrained ConvNet as an initialization for a new dataset?\na) It allows for faster training times. b) It improves the performance of the network on the new dataset. c) It reduces the risk of overfitting. d) All of the above. True/False:\nIt is always better to fine-tune a pretrained ConvNet than to use it as a fixed feature extractor. Fine-tuning all layers of a pretrained ConvNet is always the best approach. The learning rate used for fine-tuning should be higher than the learning rate used for training the new classifier. Short Answer:\nExplain why it is generally better to use a smaller learning rate for fine-tuning a pretrained ConvNet. Describe a scenario where it might be beneficial to train a linear classifier on CNN codes from an earlier layer in the pretrained network. How can you convert a fully connected layer in a ConvNet to a convolutional layer? Answer Key:\nMultiple Choice:\nd) All of the above. b) It improves the performance of the network on the new dataset. b) The activations of the hidden layers in a pretrained ConvNet. c) The number of convolutional layers in the pretrained network. d) All of the above. True/False:\nFalse False False Short Answer:\nThe weights of a pretrained ConvNet are already relatively good, so using a smaller learning rate prevents them from being distorted too quickly during fine-tuning. This helps to preserve the valuable features learned during the initial training. If the new dataset is very different from the original dataset, the features learned in the later layers of the pretrained network may not be relevant. Training a linear classifier on CNN codes from an earlier layer, which contains more generic features, can improve performance in this scenario. A fully connected layer can be converted to a convolutional layer by setting the filter size to the size of the input volume and applying it with zero padding. This effectively replicates the functionality of the fully connected layer as a convolution operation. This quiz is designed to test your understanding of the concepts of transfer learning in ConvNets. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.\n","wordCount":"1711","inLanguage":"en","image":"https://csc-bo.github.io/favicon.ico","datePublished":"2024-05-21T16:18:00+08:00","dateModified":"2024-05-21T16:18:00+08:00","author":{"@type":"Person","name":"Bo Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://csc-bo.github.io/posts/cs231_part2_quiz/"},"publisher":{"@type":"Organization","name":"Bo's Log | What I cannot create, I do not understand","logo":{"@type":"ImageObject","url":"https://csc-bo.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://csc-bo.github.io/ accesskey=h title="Bo's Log (Alt + H)"><img src=https://csc-bo.github.io/apple-touch-icon.png alt aria-label=logo height=35>Bo's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://csc-bo.github.io/ title=Home><span>Home</span></a></li><li><a href=https://csc-bo.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://csc-bo.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://csc-bo.github.io/experience/ title=Experience><span>Experience</span></a></li><li><a href=https://csc-bo.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://csc-bo.github.io/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://csc-bo.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://csc-bo.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Cs231_part2_quiz</h1><div class=post-meta><span title='2024-05-21 16:18:00 +0800 CST'>May 21, 2024</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1711 words&nbsp;·&nbsp;Bo Liu&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/cs231_part2_quiz.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#quiz-visualizing-convnets>Quiz: Visualizing ConvNets</a></li><li><a href=#transfer-learning-in-convnets-a-quiz>Transfer Learning in ConvNets: A Quiz</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>I used Gemini-1.5-flash to generate all the quizzes and answers. Enjoy!"</p><p><strong>Multiple Choice:</strong></p><ol><li><p><strong>What is the primary function of a convolutional layer in a ConvNet?</strong></p><ul><li>a) To perform matrix multiplication on the input data.</li><li>b) To extract features from the input volume by applying learnable filters.</li><li>c) To classify the input data into different categories.</li><li>d) To reduce the dimensionality of the input data.</li></ul></li><li><p><strong>What does &ldquo;local connectivity&rdquo; mean in the context of convolutional layers?</strong></p><ul><li>a) Each neuron is connected to all neurons in the previous layer.</li><li>b) Each neuron is connected to a small region of the input volume.</li><li>c) Neurons in the same depth slice share the same weights.</li><li>d) The layer&rsquo;s output is a single vector of class scores.</li></ul></li><li><p><strong>Which of the following is NOT a hyperparameter that controls the size of the output volume in a convolutional layer?</strong></p><ul><li>a) Depth</li><li>b) Stride</li><li>c) Receptive field size</li><li>d) Zero padding</li></ul></li><li><p><strong>What is the purpose of parameter sharing in convolutional layers?</strong></p><ul><li>a) To reduce the number of parameters in the network.</li><li>b) To ensure that the network is translationally invariant.</li><li>c) To allow the network to learn more complex features.</li><li>d) All of the above.</li></ul></li><li><p><strong>What is a &ldquo;depth slice&rdquo; in a convolutional layer?</strong></p><ul><li>a) A 2D slice of the output volume, where all neurons share the same weights.</li><li>b) A 3D volume representing the input to the convolutional layer.</li><li>c) A single neuron in the convolutional layer.</li><li>d) The set of all neurons connected to a specific region of the input volume.</li></ul></li></ol><p><strong>True/False:</strong></p><ol><li><strong>Convolutional layers are only used in image processing tasks.</strong></li><li><strong>Zero padding is always necessary to preserve the spatial size of the input volume.</strong></li><li><strong>The stride hyperparameter determines the size of the receptive field.</strong></li><li><strong>A convolutional layer can be implemented as a matrix multiplication operation.</strong></li></ol><p><strong>Short Answer:</strong></p><ol><li><strong>Explain the concept of a &ldquo;filter&rdquo; in a convolutional layer.</strong></li><li><strong>How does the stride hyperparameter affect the size of the output volume?</strong></li><li><strong>Give an example of how parameter sharing contributes to translation invariance in a ConvNet.</strong></li></ol><p><strong>Answer Key:</strong></p><p><strong>Multiple Choice:</strong></p><ol><li>b) To extract features from the input volume by applying learnable filters.</li><li>b) Each neuron is connected to a small region of the input volume.</li><li>c) Receptive field size</li><li>d) All of the above.</li><li>a) A 2D slice of the output volume, where all neurons share the same weights.</li></ol><p><strong>True/False:</strong></p><ol><li>False</li><li>False</li><li>False</li><li>True</li></ol><p><strong>Short Answer:</strong></p><ol><li>A filter in a convolutional layer is a set of weights that is applied to a small region of the input volume. The filter learns to detect a specific feature, such as an edge or a texture.</li><li>A larger stride results in a smaller output volume, as the filter skips over more pixels in the input volume.</li><li>If a ConvNet learns to detect a horizontal edge in one part of the image, parameter sharing ensures that it can also detect that edge in other parts of the image without needing to learn separate weights for each location. This makes the network translationally invariant.</li></ol><p>This quiz is designed to test your understanding of the core concepts related to convolutional layers. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.</p><h2 id=quiz-visualizing-convnets>Quiz: Visualizing ConvNets<a hidden class=anchor aria-hidden=true href=#quiz-visualizing-convnets>#</a></h2><p>This quiz focuses on understanding how to visualize and interpret what Convolutional Neural Networks (ConvNets) learn, based on the information from the CS231n website.</p><p><strong>Multiple Choice:</strong></p><ol><li><p><strong>Which of the following is NOT a common technique for visualizing ConvNets?</strong></p><ul><li>a) Visualizing activations of different layers.</li><li>b) Visualizing the weights of filters.</li><li>c) Occluding parts of the image to see how the prediction changes.</li><li>d) Using a fully connected layer to classify the input image.</li></ul></li><li><p><strong>What can be inferred from seeing noisy patterns in the visualized weights of a ConvNet?</strong></p><ul><li>a) The network has been trained for a long time.</li><li>b) The network is overfitting the training data.</li><li>c) The network is performing well on unseen data.</li><li>d) The network has a high regularization strength.</li></ul></li><li><p><strong>What is a potential drawback of visualizing the images that maximally activate a neuron?</strong></p><ul><li>a) It can be difficult to understand the meaning of a single neuron in isolation.</li><li>b) It doesn&rsquo;t provide information about the spatial relationships between features.</li><li>c) It requires a large dataset of images for visualization.</li><li>d) All of the above.</li></ul></li><li><p><strong>What is the purpose of using t-SNE to embed CNN codes?</strong></p><ul><li>a) To visualize the high-dimensional representation space of a ConvNet in two dimensions.</li><li>b) To understand the spatial relationships between features learned by the network.</li><li>c) To determine the optimal number of filters for a convolutional layer.</li><li>d) To reduce the number of parameters in the network.</li></ul></li><li><p><strong>What information can be obtained by occluding parts of an image and observing the change in classification probability?</strong></p><ul><li>a) Which parts of the image are most important for the network&rsquo;s prediction.</li><li>b) The specific features that the network is learning to detect.</li><li>c) The size of the receptive field for each neuron in the network.</li><li>d) The number of hidden layers required for accurate classification.</li></ul></li></ol><p><strong>True/False:</strong></p><ol><li><strong>Visualizing activations can help identify &ldquo;dead filters&rdquo; in a ConvNet.</strong></li><li><strong>t-SNE is the only method for visualizing high-dimensional data in a low-dimensional space.</strong></li><li><strong>Occlusion methods can be used to understand the spatial relationships between features learned by the network.</strong></li></ol><p><strong>Short Answer:</strong></p><ol><li><strong>Explain why visualizing the weights of the first convolutional layer is often more interpretable than visualizing weights in deeper layers.</strong></li><li><strong>Describe one limitation of using t-SNE to visualize CNN codes.</strong></li><li><strong>What is the difference between visualizing activations and visualizing weights in a ConvNet?</strong></li></ol><p><strong>Answer Key:</strong></p><p><strong>Multiple Choice:</strong></p><ol><li>d) Using a fully connected layer to classify the input image.</li><li>b) The network is overfitting the training data.</li><li>d) All of the above.</li><li>a) To visualize the high-dimensional representation space of a ConvNet in two dimensions.</li><li>a) Which parts of the image are most important for the network&rsquo;s prediction.</li></ol><p><strong>True/False:</strong></p><ol><li>True</li><li>False</li><li>True</li></ol><p><strong>Short Answer:</strong></p><ol><li>The first convolutional layer operates directly on raw pixel data, making the filters easier to interpret as they learn simple features like edges, textures, and colors. Deeper layers learn more abstract and complex features, making their weights harder to understand visually.</li><li>t-SNE can sometimes distort the relationships between points in the high-dimensional space, especially when dealing with very large datasets. It can also be sensitive to the choice of hyperparameters.</li><li>Visualizing activations shows the output of each neuron in a layer for a given input image. Visualizing weights shows the filters learned by the convolutional layer, which represent the patterns the network is looking for in the input data.</li></ol><p>This quiz is designed to help you understand the different techniques for visualizing and interpreting ConvNets. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.</p><h2 id=transfer-learning-in-convnets-a-quiz>Transfer Learning in ConvNets: A Quiz<a hidden class=anchor aria-hidden=true href=#transfer-learning-in-convnets-a-quiz>#</a></h2><p>This quiz focuses on the concepts of transfer learning in convolutional neural networks, as explained on the CS231n website.</p><p><strong>Multiple Choice:</strong></p><ol><li><p><strong>Why is it uncommon to train a ConvNet from scratch?</strong></p><ul><li>a) It requires a large amount of data.</li><li>b) It is computationally expensive.</li><li>c) It is difficult to find good initial weights.</li><li>d) All of the above.</li></ul></li><li><p><strong>What is the primary benefit of using a pretrained ConvNet as a fixed feature extractor?</strong></p><ul><li>a) It allows for faster training times.</li><li>b) It improves the performance of the network on the new dataset.</li><li>c) It reduces the risk of overfitting.</li><li>d) It enables the use of smaller datasets.</li></ul></li><li><p><strong>What are &ldquo;CNN codes&rdquo;?</strong></p><ul><li>a) The weights of the convolutional layers in a pretrained ConvNet.</li><li>b) The activations of the hidden layers in a pretrained ConvNet.</li><li>c) The output of the classifier layer in a pretrained ConvNet.</li><li>d) The input images used to train a pretrained ConvNet.</li></ul></li><li><p><strong>Which of the following is NOT a factor to consider when deciding whether to fine-tune a pretrained ConvNet?</strong></p><ul><li>a) The size of the new dataset.</li><li>b) The similarity of the new dataset to the original dataset.</li><li>c) The number of convolutional layers in the pretrained network.</li><li>d) The learning rate used for training the new classifier.</li></ul></li><li><p><strong>What is the main advantage of using a pretrained ConvNet as an initialization for a new dataset?</strong></p><ul><li>a) It allows for faster training times.</li><li>b) It improves the performance of the network on the new dataset.</li><li>c) It reduces the risk of overfitting.</li><li>d) All of the above.</li></ul></li></ol><p><strong>True/False:</strong></p><ol><li><strong>It is always better to fine-tune a pretrained ConvNet than to use it as a fixed feature extractor.</strong></li><li><strong>Fine-tuning all layers of a pretrained ConvNet is always the best approach.</strong></li><li><strong>The learning rate used for fine-tuning should be higher than the learning rate used for training the new classifier.</strong></li></ol><p><strong>Short Answer:</strong></p><ol><li><strong>Explain why it is generally better to use a smaller learning rate for fine-tuning a pretrained ConvNet.</strong></li><li><strong>Describe a scenario where it might be beneficial to train a linear classifier on CNN codes from an earlier layer in the pretrained network.</strong></li><li><strong>How can you convert a fully connected layer in a ConvNet to a convolutional layer?</strong></li></ol><p><strong>Answer Key:</strong></p><p><strong>Multiple Choice:</strong></p><ol><li>d) All of the above.</li><li>b) It improves the performance of the network on the new dataset.</li><li>b) The activations of the hidden layers in a pretrained ConvNet.</li><li>c) The number of convolutional layers in the pretrained network.</li><li>d) All of the above.</li></ol><p><strong>True/False:</strong></p><ol><li>False</li><li>False</li><li>False</li></ol><p><strong>Short Answer:</strong></p><ol><li>The weights of a pretrained ConvNet are already relatively good, so using a smaller learning rate prevents them from being distorted too quickly during fine-tuning. This helps to preserve the valuable features learned during the initial training.</li><li>If the new dataset is very different from the original dataset, the features learned in the later layers of the pretrained network may not be relevant. Training a linear classifier on CNN codes from an earlier layer, which contains more generic features, can improve performance in this scenario.</li><li>A fully connected layer can be converted to a convolutional layer by setting the filter size to the size of the input volume and applying it with zero padding. This effectively replicates the functionality of the fully connected layer as a convolution operation.</li></ol><p>This quiz is designed to test your understanding of the concepts of transfer learning in ConvNets. Remember that the CS231n website provides a wealth of information and resources to further explore these topics.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://csc-bo.github.io/posts/cs231_part1_quiz/><span class=title>Next »</span><br><span>CS231_part1_quiz</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://csc-bo.github.io/>Bo's Log | What I cannot create, I do not understand</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script></body></html>